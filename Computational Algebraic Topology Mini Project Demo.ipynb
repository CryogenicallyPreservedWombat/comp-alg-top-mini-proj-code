{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d983589e-6a02-407c-9df1-f88824ce33a9",
   "metadata": {},
   "source": [
    "# Cosheaf Homology with Discrete Morse Theory & the Mayer-Vietoris Sequence\n",
    "\n",
    "Over the course of this project, we have defined cosheaves on simplicial complexes and explained how each has a sequence of homology groups. We have focused in particular on how an analog of the Mayer-Vietoris sequence that exists in simplicial homology persists in the context of cosheaves. To simplify calculations, we have also investigated how discrete Morse theoretic techniques may be adapted to this context.\n",
    "\n",
    "In this notebook, we will provide some software implementations of relevant ideas from the course, including a definition of simplicial complexes and chain complexes, which is where we will begin. We will look at how discrete Morse theory in some sense simplifies this calculation, before essentially repeating the process for cosheaves. We conclude with an examination of the Mayer-Vietoris sequence from these perspectives.\n",
    "\n",
    "Note that all of the code written in this notebook was written explicitly for (and over the duration of) the mini project for Computational Algebraic Topology 2024/2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4075088-5026-48bd-a0c7-273d9a70ebaf",
   "metadata": {},
   "source": [
    "## 1 Simplicial Complexes and Homology\n",
    "\n",
    "We introduce a class capturing most of the salient features of a simplicial complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931652f-e5aa-4ef9-a60c-3bb32e3d881d",
   "metadata": {},
   "source": [
    "### 1.1 Simplicial Complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f0669c7-9b94-452c-b649-c61e75a72552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from copy import copy\n",
    "\n",
    "Simplex = frozenset\n",
    "\n",
    "def union(sets):\n",
    "    return reduce(lambda x, y : x.union(y), sets, set())\n",
    "\n",
    "def all_satisfy(predicate, iterable):\n",
    "    return all(map(predicate, iterable))\n",
    "\n",
    "def faces(simplex):\n",
    "    if len(simplex) <= 1:\n",
    "        return { }\n",
    "    \n",
    "    return set(map(lambda v : simplex - { v }, simplex))\n",
    "\n",
    "def subsimplices(simplex):\n",
    "    if not simplex:\n",
    "        return {}\n",
    "    \n",
    "    return union(map(lambda face : subsimplices(face), faces(simplex))).union({ simplex })\n",
    "\n",
    "simp_str = lambda simplex : f\"{sorted(simplex)}\"\n",
    "dim = lambda simplex : len(simplex) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9619f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplicialComplex:\n",
    "    def __init__(self, simplices: set[Simplex], no_assert=False):\n",
    "        if not no_assert:\n",
    "            included = lambda simplex : simplex in simplices\n",
    "            faces_included = lambda simplex : all_satisfy(included, faces(simplex))\n",
    "            assert(all_satisfy(faces_included, simplices))\n",
    "        \n",
    "        self.simplices = simplices\n",
    "    \n",
    "    def vertices(self):\n",
    "        return union(self.simplices)\n",
    "    \n",
    "    def __contains__(self, simplex: Simplex) -> bool:\n",
    "        return simplex in self.simplices\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.simplices.__iter__()\n",
    "\n",
    "    @staticmethod\n",
    "    def generated_by(simplices: set[Simplex]):\n",
    "        all_simplices = union(map(lambda simplex : subsimplices(simplex), simplices))\n",
    "        return SimplicialComplex(all_simplices)\n",
    "    \n",
    "    @staticmethod\n",
    "    def ball(n: int):\n",
    "        interior = Simplex(range(n + 1))\n",
    "        return SimplicialComplex.generated_by({interior})\n",
    "    \n",
    "    @staticmethod\n",
    "    def sphere(n: int):\n",
    "        ball = SimplicialComplex.ball(n + 1)\n",
    "        return SimplicialComplex(ball.simplices - { max(ball.simplices) })\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        n = max(self.vertices()) ** 2 if self.simplices else 0\n",
    "        sorted_simplices = sorted(self.simplices, key=simp_str)\n",
    "        return \"SimplicialComplex(simplices:\" + \", \".join(map(simp_str, sorted_simplices)) + \")\"\n",
    "    \n",
    "    # Not a super useful operation but should make certain constructions (e.g disjoint union or wedge sums) easier.\n",
    "    def glue(self, other_complex, along=None):\n",
    "        shift = (0 if not self.vertices() else max(self.vertices())) - (0 if not other_complex.vertices() else min(other_complex.vertices())) + 1\n",
    "        shift_simplex = lambda simplex : Simplex(map(lambda x : x + shift, simplex))\n",
    "\n",
    "        shifted_complex = SimplicialComplex(set(map(shift_simplex, other_complex.simplices)))\n",
    "\n",
    "        sum_complex = SimplicialComplex(self.simplices.union(shifted_complex.simplices))\n",
    "\n",
    "        if not along:\n",
    "            return sum_complex\n",
    "        \n",
    "        along = { key : value + shift for key, value in along.items() }\n",
    "\n",
    "        modify_simplex = lambda simplex : Simplex({ along[v] if v in along else v for v in simplex })\n",
    "        glued_simplices = set(map(lambda simplex : modify_simplex(simplex), sum_complex.simplices))\n",
    "        return SimplicialComplex(glued_simplices).cleaned_vertex_labels()\n",
    "\n",
    "    def wedge(self, other_complex):\n",
    "        return self.glue(other_complex, along = { 0 : 0 })\n",
    "\n",
    "    def clean_vertex_labels(self) -> None:\n",
    "        vertices = sorted(self.vertices())\n",
    "        dict = { y : x for x, y in enumerate(vertices) }\n",
    "        cleaned_simplices = set(map(lambda simplex : Simplex(map(lambda vertex : dict[vertex], simplex)), self.simplices))\n",
    "        self.simplices = cleaned_simplices\n",
    "\n",
    "    def cleaned_vertex_labels(self):\n",
    "        c = copy(self)\n",
    "        c.clean_vertex_labels()\n",
    "        return c\n",
    "\n",
    "SC = SimplicialComplex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62404c77",
   "metadata": {},
   "source": [
    "### 1.2 Chain Complexes and Homology\n",
    "\n",
    "We encode the chain complexes as a sequence of matrices representing the boundary operators. Implicity, we take our base field to be $\\mathbb R$ in this notebook and therefore consider $C_\\bullet(K, \\mathbb R)$ in this subsection.\n",
    "First we'll write some code to help find a basis for the homology of a chain complex given maps \n",
    "$$\\cdots \\to C_{n + 1} \\xrightarrow{\\partial_{n + 1}} C_n \\xrightarrow{\\partial_n} C_{n - 1} \\to \\cdots .$$\n",
    "\n",
    "We will make use of the inner space structure on $\\mathbb R^n$ via the isomorphism $H_n(C_\\bullet, \\partial_\\bullet) = \\ker \\partial_n / {\\rm im} \\, \\partial_{n + 1} \\cong ({\\rm im}\\, \\partial_{n + 1})^\\bot$, where the orthogonal complement is taken in the ambient space $\\ker \\partial_n$.\n",
    "Any integer manipulations below are to try to ensure that the resulting basis has integer coefficients, so that the vectors are a bit more geometrically interpretable as combinations of simplices in the underlying simplicial complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "936ed43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "too_small = lambda m : np.all(np.isclose(np.array(m).astype(float), 0.0)) # the bugs I have chased due to `.is_zero_matrix` not being sensitive to floating point errors...\n",
    "\n",
    "from sympy import Matrix, BlockMatrix, lcm\n",
    "import numpy as np\n",
    "\n",
    "def orthogonalize(A : np.array) -> tuple[Matrix, Matrix]:\n",
    "    \"\"\"\n",
    "    Does not handle empty matrices very well! User beware!\n",
    "    \"\"\"\n",
    "    dtype = int if all(x.is_integer for x in A) else float\n",
    "\n",
    "    A = Matrix(A)\n",
    "    Q = Matrix(np.identity(A.cols, dtype=dtype))\n",
    "\n",
    "    for i in range(A.cols):\n",
    "        Q_term = Matrix(np.identity(A.cols, dtype=dtype))\n",
    "        \n",
    "        col = A.col(i)\n",
    "\n",
    "        for j in range(i):\n",
    "            old_col = (A * Q).col(j)\n",
    "            Q_term[j, i] = -col.dot(old_col) / old_col.dot(old_col) if not too_small(old_col) else 0\n",
    "\n",
    "        if dtype == int:\n",
    "            lcd = lcm([ x.denominator for x in (A * Q_term)[:, i]])\n",
    "            Q_term[:, i] *= lcd # / g\n",
    "\n",
    "        Q = Q * Q_term\n",
    "        \n",
    "    return A * Q, Q\n",
    "\n",
    "def left_inverse(A: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Note the input matrix A is assumed to be injective, lest this task be impossible.\n",
    "    \"\"\"\n",
    "    # this has taken me many attempts because I am embarrassingly bad at linear algebra.\n",
    "    # write Q = AR where Q is orthogonal. Then Q^T(Q^T Q)^{-1} Q = Q^T(Q^T Q)^{-1} (AR) = I, so A has left inverse R Q^T(Q^T Q)^{-1}\n",
    "\n",
    "    if not all(A.shape):\n",
    "        return np.eye(A.shape[1], A.shape[0]) # i.e if A is the 0 map from a 0 dimensional space then sure the identity is a right inverse since 0 a\n",
    "\n",
    "    A = Matrix(A)\n",
    "\n",
    "    Q, R = orthogonalize(A)\n",
    "\n",
    "    D = (Q.transpose() @ Q).inv() @ Q.transpose()\n",
    "\n",
    "    return np.array(R @ D).astype(float)\n",
    "\n",
    "def right_inverse(A: np.array) -> np.array:\n",
    "    if not all(A.shape): # if the matrix is empty\n",
    "        return np.identity(A.shape[0])\n",
    "    \n",
    "    A = Matrix(A)\n",
    "\n",
    "    return left_inverse(A.transpose()).transpose()\n",
    "\n",
    "\n",
    "def null_space(A: np.array):\n",
    "    A = Matrix(A)\n",
    "    ker = A.nullspace()\n",
    "\n",
    "    dtype = int if all(x.is_integer for x in A) else float\n",
    "\n",
    "    return Matrix.hstack(*[\n",
    "        (col * lcm([ q.denominator for q in col ]) if dtype == int else col) for col in ker\n",
    "    ])\n",
    "\n",
    "def homology_basis(boundary_n: np.array, boundary_n_plus_one: np.array, degree_n: int) -> np.array:\n",
    "    boundary_n = Matrix(boundary_n)\n",
    "    boundary_n_plus_one = Matrix(boundary_n_plus_one)\n",
    "\n",
    "    ker = null_space(boundary_n)\n",
    "\n",
    "    img, _ = orthogonalize(boundary_n_plus_one)\n",
    "\n",
    "    if not any(ker.shape):\n",
    "        return np.zeros((degree_n, 0))\n",
    "    \n",
    "    aug_matrix = Matrix(BlockMatrix([img, ker])) if any(img.shape) else ker\n",
    "    orthog, _ = orthogonalize(aug_matrix)\n",
    "\n",
    "    return np.array(Matrix.hstack(*[\n",
    "        orthog.col(i) for i in range(img.cols, orthog.cols) if not too_small(orthog.col(i))\n",
    "    ])).astype(float).reshape((degree_n, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e18e3ad",
   "metadata": {},
   "source": [
    "We will ensure that the boundary maps defined satisfy $\\partial_{n - 1} \\circ \\partial_n = 0$ for each $n$, to try to more faithfully represent the mathematical object we are attempting to capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe8889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import latex\n",
    "\n",
    "rank = lambda m : 0 if 0 in m.shape else np.linalg.matrix_rank(m)\n",
    "\n",
    "class ChainComplex:\n",
    "    def __init__(self, degrees: tuple[int], boundary_maps: tuple[np.array]) -> None:\n",
    "        self.__degrees = degrees\n",
    "        self.__boundary_maps = [np.array(x) for x in boundary_maps]\n",
    "        self.test_dims()\n",
    "        self.test_square_to_zero()\n",
    "        self.should_display_with_matrices = False\n",
    "    \n",
    "    def test_dims(self):\n",
    "        assert all_satisfy(\n",
    "            lambda i : self.boundary_map(i).shape == (self.degree(i - 1), self.degree(i)),\n",
    "            range(self.max_dim() + 2)\n",
    "        ), f\"Boundary maps have unexpected shapes {[ self.boundary_map(i).shape for i in range(self.max_dim() + 2) ]} for degrees {[self.degree(i) for i in range(self.max_dim() + 2)]}\"\n",
    "\n",
    "    def test_square_to_zero(self):\n",
    "        assert all_satisfy(\n",
    "            lambda i : np.all(np.isclose(self.boundary_map(i - 1) @ self.boundary_map(i), 0.0)),\n",
    "            range(self.max_dim() + 2)\n",
    "        ), f\"Boundary maps do not square to zero! {[self.boundary_map(i - 1) @ self.boundary_map(i) for i in range(self.max_dim())]} \\n\\n\\n\\nhere are the maps:\\n\\n\\n\\n {self.__boundary_maps}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def builder(degrees: tuple[int], boundary_builder):\n",
    "        return ChainComplex(\n",
    "            degrees,\n",
    "            list(map(boundary_builder, degrees))\n",
    "        )\n",
    "\n",
    "    def degree(self, i: int) -> int:\n",
    "        if 0 <= i and i < len(self.__degrees):\n",
    "            return self.__degrees[i]\n",
    "        return 0\n",
    "    \n",
    "    def max_dim(self) -> int:\n",
    "        return len(self.__degrees) - 1\n",
    "    \n",
    "    def boundary_map(self, i: int) -> np.array:\n",
    "        if 0 < i and i < self.max_dim() + 1:\n",
    "            return self.__boundary_maps[i]\n",
    "        if i == self.max_dim() + 1:\n",
    "            return np.zeros((self.degree(i - 1), 0))\n",
    "        if i == 0:\n",
    "            return np.zeros((0, self.degree(0)))\n",
    "\n",
    "        return np.zeros((0, 0))\n",
    "\n",
    "    def sum(self, other_complex):\n",
    "        max_i = max(self.max_dim(), other_complex.max_dim())\n",
    "\n",
    "        first_diag = lambda i : self.boundary_map(i)\n",
    "        second_diag = lambda i : other_complex.boundary_map(i)\n",
    "\n",
    "        up_right = lambda i : np.zeros((\n",
    "            self.degree(i - 1), other_complex.degree(i)\n",
    "        ))\n",
    "        bot_left = lambda i : np.zeros((\n",
    "            other_complex.degree(i - 1), self.degree(i)\n",
    "        ))\n",
    "        \n",
    "        sum_degrees = [ self.degree(i) + other_complex.degree(i) for i in range(max_i + 1)]\n",
    "        sum_maps = [\n",
    "            np.block([\n",
    "                [first_diag(i),  up_right(i)],\n",
    "                [bot_left(i),    second_diag(i)]\n",
    "            ]) for i in range(max_i + 1)\n",
    "        ]\n",
    "\n",
    "        return ChainComplex(\n",
    "            degrees=sum_degrees,\n",
    "            boundary_maps=sum_maps,\n",
    "        )\n",
    "    \n",
    "    def homology_basis(self, n: int):\n",
    "        return homology_basis(boundary_n=self.boundary_map(n), boundary_n_plus_one=self.boundary_map(n + 1), degree_n=self.degree(n))\n",
    "    \n",
    "    def betti_number(self, n: int) -> int:\n",
    "        return self.degree(n) - rank(self.boundary_map(n)) - rank(self.boundary_map(n + 1))\n",
    "\n",
    "    def display_with_matrices(self, val: bool=True):\n",
    "        self.should_display_with_matrices = val\n",
    "        return self\n",
    "\n",
    "    def _repr_latex_(self) -> str:\n",
    "        arrow = lambda i : (latex(Matrix(self.boundary_map(i))) if all(self.boundary_map(i).shape) else '') if self.should_display_with_matrices else \"\\\\partial_\" + str(i)\n",
    "        space = lambda i : \"\\\\mathbb R^{\" + str(self.degree(i)) if self.degree(i) else \"{0\"\n",
    "\n",
    "        return f\"$$\\\\cdots \\\\to 0 \\\\to \" + f\"\".join([\n",
    "            space(i) + \"} \\\\xrightarrow{\" + arrow(i) + \"}\" for i in range(self.max_dim(), 0, -1)\n",
    "        ]) + space(0) + \"} \\\\to 0 \\\\to \\\\cdots$$\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \" --> \".join(reversed([ str(x) for x in self.__degrees ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a3c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of a simplex in another [σ : τ]\n",
    "def order(sigma: Simplex, tau: Simplex) -> int:\n",
    "    if sigma not in faces(tau):\n",
    "        return 0\n",
    "    return 1 if sorted(tau).index(min(tau - sigma)) % 2 == 0 else -1\n",
    "\n",
    "def _boundary_map(complex: SimplicialComplex, n: int) -> np.array:\n",
    "    # bucket simplices by dimension and sort them in a semi-reasonable way for prettiness\n",
    "    domain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, complex.simplices), key=simp_str)\n",
    "    codomain_simplices = sorted(filter(lambda simplex : dim(simplex) == n - 1, complex.simplices), key=simp_str)\n",
    "\n",
    "    rows = len(codomain_simplices)\n",
    "    cols = len(domain_simplices)\n",
    "\n",
    "    if rows == 0 and cols == 0:\n",
    "        return np.zeros((0, 0))\n",
    "    if rows == 0:\n",
    "        return np.zeros((0, cols))\n",
    "    if cols == 0:\n",
    "        return np.zeros((rows, 0))\n",
    "        \n",
    "    return np.array([\n",
    "        [ order(codomain_simplices[i], domain_simplices[j]) for j in range(cols) ] for i in range(rows)\n",
    "    ])\n",
    "\n",
    "def chain_complex(K: SimplicialComplex) -> ChainComplex:\n",
    "    n = max(map(dim, K)) + 1\n",
    "\n",
    "    return ChainComplex(\n",
    "        degrees=[ sum([ dim(s) == i for s in K ]) for i in range(n) ],\n",
    "        boundary_maps= [ _boundary_map(K, i) for i in range(n) ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c48d12",
   "metadata": {},
   "source": [
    "### 1.2.1 Example: Homology of a Torus\n",
    "\n",
    "As a first example, we will look at the homology of the torus $S^1 \\times S^1$. First we compute the relevant chain complex $C_\\bullet(S^1 \\times S^1; \\mathbb R)$, using the simplicial complex obtained by cutting each square in a $3 \\times 3$ grid into $2$ triangles and then gluing opposite sides of the grid together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f508270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to \\mathbb R^{18} \\xrightarrow{\\partial_2}\\mathbb R^{27} \\xrightarrow{\\partial_1}\\mathbb R^{9} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "18 --> 27 --> 9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torus_to_line = lambda x, y : 3 * (x % 3) + (y % 3)\n",
    "\n",
    "T = SimplicialComplex.generated_by(\n",
    "    {\n",
    "        Simplex({ torus_to_line(x, y), torus_to_line(x + 1, y), torus_to_line(x + 1, y + 1) }) for x in range(3) for y in range(3)\n",
    "    }.union({\n",
    "        Simplex({ torus_to_line(x, y), torus_to_line(x, y + 1), torus_to_line(x + 1, y + 1) }) for x in range(3) for y in range(3)\n",
    "    })\n",
    ")\n",
    "\n",
    "C = chain_complex(T)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362c58b",
   "metadata": {},
   "source": [
    "Then we compute its Betti number in degrees 0, 1, and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e804c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0-th homology space of the torus is 1 dimensional.\n",
      "The 1-th homology space of the torus is 0 dimensional.\n",
      "The 2-th homology space of the torus is 0 dimensional.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"The {i}-th homology space of the torus is {C.betti_number(i)} dimensional.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a297b",
   "metadata": {},
   "source": [
    "This is thankfully what we expect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460fd0a",
   "metadata": {},
   "source": [
    "### 1.3 Simplifying with Discrete Morse Theory\n",
    "\n",
    "Pairing simplices into an acyclic partial matching leaves behind a small set of critical simplices that may be seen as generators of a Morse chain complex, whose homology agrees with the ordinary one. We define a partial matching here and implement the algorithm suggested in the course notes to build its Morse complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2762163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "class SimplexPair:\n",
    "    def __init__(self, source: Simplex, target: Simplex) -> None:\n",
    "        assert(source.issubset(target) and len(target - source) == 1)\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "    \n",
    "    def both(self) -> set[Simplex]:\n",
    "        return { self.source, self.target }\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"({simp_str(self.source)} ◃ {simp_str(self.target)})\"\n",
    "\n",
    "    def __eq__(self, value: object) -> bool:\n",
    "        return value.__repr__() == self.__repr__()\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return self.__repr__().__hash__()\n",
    "\n",
    "class PartialMatching:\n",
    "    def __init__(self, complex: SimplicialComplex, pairs: set[SimplexPair], no_assert=False) -> None:\n",
    "        if not no_assert:\n",
    "            # no simplex belongs to more than one pair\n",
    "            assert(all_satisfy(lambda pair : all_satisfy(lambda other_pair : pair == other_pair or pair.both().isdisjoint(other_pair.both()), pairs), pairs))\n",
    "            assert(union(map(lambda pair : pair.both(), pairs)).issubset(complex.simplices))\n",
    "\n",
    "        self.pairs = pairs\n",
    "        self.complex = complex\n",
    "\n",
    "    def sources(self) -> set[Simplex]:\n",
    "        return { pair.source for pair in self.pairs }\n",
    "    \n",
    "    def targets(self) -> set[Simplex]:\n",
    "        return { pair.target for pair in self.pairs }\n",
    "    \n",
    "    def simplices(self) -> set[Simplex]:\n",
    "        return union([pair.both() for pair in self.pairs])\n",
    "\n",
    "    def critical(self) -> set[Simplex]:\n",
    "        return self.complex.simplices - union([pair.both() for pair in self.pairs])\n",
    "    \n",
    "    def restrict(self, complex: SimplicialComplex):\n",
    "        return PartialMatching(complex, set( [ p for p in self.pairs if p.source in complex ]))\n",
    "\n",
    "    def __getitem__(self, simplex: Simplex) -> Simplex:\n",
    "        for pair in self.pairs:\n",
    "            if pair.source == simplex:\n",
    "                return pair.target\n",
    "        return None\n",
    "    \n",
    "    def __contains__(self, simplex: Simplex) -> bool:\n",
    "        return simplex in union([ pair.both() for pair in self.pairs ])\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return \", \".join([ pair.__repr__() for pair in self.pairs ])\n",
    "    \n",
    "    def __paths(self, origin: Simplex) -> list[Simplex]:\n",
    "        if not self.pairs:\n",
    "            return [[]]\n",
    "\n",
    "        possible_faces = set(faces(origin)).intersection(self.sources())\n",
    "        new_origin = lambda face : self[face]\n",
    "        smaller_matching = lambda face : PartialMatching(self.complex, self.pairs - { SimplexPair(face, new_origin(face)) }, no_assert=True)\n",
    "\n",
    "        return [\n",
    "            [face, new_origin(face)] + p for face in possible_faces for p in smaller_matching(face).__paths(new_origin(face))\n",
    "        ] + [[]]\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def paths(self) -> set[tuple]:\n",
    "        length_bucketed_matchings = [\n",
    "            PartialMatching(self.complex, set(filter(lambda pair : len(pair.source) - 1 == n, self.pairs)), no_assert=True) for n in range(max(map(len, self.complex)))\n",
    "        ]\n",
    "\n",
    "        paths_as_list: list[list] = sum([\n",
    "            length_bucketed_matchings[len(sigma) - 2].__paths(origin=sigma) for sigma in self.complex if len(sigma) > 1 \n",
    "        ], start=[])\n",
    "        \n",
    "        return { tuple(p) for p in paths_as_list }\n",
    "    \n",
    "    @lru_cache(maxsize=None)\n",
    "    def critical_paths(self) -> set[tuple]:\n",
    "        # print(\"not yet cached\")\n",
    "        length_bucketed_matchings = [\n",
    "            PartialMatching(self.complex, set(filter(lambda pair : len(pair.source) - 1 == n, self.pairs)), no_assert=True) for n in range(max(map(len, self.complex)))\n",
    "        ]\n",
    "\n",
    "        paths_as_list: list[list] = sum([\n",
    "            length_bucketed_matchings[len(sigma) - 2].__paths(origin=sigma) for sigma in self.critical() if len(sigma) > 1 \n",
    "        ], start=[])\n",
    "        \n",
    "        return { tuple(p) for p in paths_as_list if not p or not set(faces(p[-1])).isdisjoint(self.critical()) }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af77bf",
   "metadata": {},
   "source": [
    "### 1.3.1 Note on Complexity\n",
    "\n",
    "It's worth mentioning here that the algorithm we have provided to find paths is not particularly quick: it generates the paths originating at a simplex $\\sigma$ recursively by adding a pair $\\alpha < \\beta$ in $\\Sigma$ that borders $\\sigma$ to the path, and then considering all paths beginning at a vertex bordering $\\beta$ using pairs in $\\Sigma \\setminus \\{ \\alpha < \\beta \\}$. Thus if $\\Sigma$ contains $n$ pairs and the maximal dimension of a vertex in the simplicial complex is $d$, we can bound our complexity by a recurrence of the form $f(n) \\leq d f(n - 1)$, which implies at worst exponential growth.\n",
    "\n",
    "There are some simplifications we have made, for instance by noting that in our application we need only consider paths that connect critical simplices, but empirically this seems to be the slowest part of generating the Morse complex.\n",
    "A benefit of this is that it needs only to be done once: thereafter all spaces tend to be small and all matrix operations are quick.\n",
    "\n",
    "The code used to generate acyclic partial matchings is comparatively faster: it loops over simplices twice and after each inner loop either matches two simplices together or marks a simplex as critical, so that each loop runs at most $n$ times, where $n$ is the number of simplices in the initial complex. Since we do sort the list of simplices in the outer loop, we should technically report that the complexity of this function is $O(n^2 \\log n)$, since the set operations in the inner loop are fast and require time proportional to the number of faces of a simplex, which is at most logarithmic in the number of simplices anyhow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1247b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acyclic_partial_matching(complex: SimplicialComplex, extra_conditions=lambda _ : True) -> PartialMatching:\n",
    "    unassigned_simplices = copy(complex.simplices)\n",
    "    pairs: set[SimplexPair] = set()\n",
    "\n",
    "    while unassigned_simplices:\n",
    "        found_good_pair = False\n",
    "\n",
    "        for simplex in copy(unassigned_simplices):\n",
    "            unassigned_faces = set(faces(simplex)).intersection(unassigned_simplices)\n",
    "            \n",
    "            if not found_good_pair and len(unassigned_faces) == 1 and extra_conditions(SimplexPair(source=min(unassigned_faces), target=simplex)):\n",
    "                face = unassigned_faces.pop()\n",
    "                                \n",
    "                pairs.add(SimplexPair(face, simplex))\n",
    "                unassigned_simplices.remove(simplex)\n",
    "                unassigned_simplices.remove(face)\n",
    "                \n",
    "                found_good_pair = True\n",
    "        \n",
    "        if not found_good_pair:\n",
    "            crit = min(sorted(unassigned_simplices, key=len))\n",
    "            unassigned_simplices.remove(crit)\n",
    "    \n",
    "    return PartialMatching(complex, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae663c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(path: list[Simplex]):\n",
    "    terms = [ \n",
    "            -order(path[i], path[i + 1]) if i % 2 == 0 \n",
    "        else order(path[i + 1], path[i]) \n",
    "        for i in range(len(path) - 1 ) \n",
    "    ]\n",
    "    \n",
    "    return reduce(lambda x, y : x * y, terms, 1)\n",
    "\n",
    "def morse_order(paths, sigma: Simplex, tau: Simplex):\n",
    "    return order(sigma, tau) + sum([ order(p[0], tau) * weight(p) * order(sigma, p[-1]) for p in paths if p ])\n",
    "\n",
    "def _morse_boundary_map(matching: PartialMatching, n: int):\n",
    "    critical_simplices = matching.critical()\n",
    "\n",
    "    # bucket simplices by dimension and sort them in a semi-reasonable way for prettiness\n",
    "    domain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, critical_simplices), key=simp_str)\n",
    "    codomain_simplices = sorted(filter(lambda simplex : dim(simplex) == n - 1, critical_simplices), key=simp_str)\n",
    "\n",
    "    rows = len(codomain_simplices)\n",
    "    cols = len(domain_simplices)\n",
    "\n",
    "    if rows == 0 and cols == 0:\n",
    "        return np.zeros((0, 0))\n",
    "    if rows == 0:\n",
    "        return np.zeros((0, cols))\n",
    "    if cols == 0:\n",
    "        return np.zeros((rows, 0))\n",
    "    \n",
    "    all_paths = matching.critical_paths()\n",
    "\n",
    "    # print(all_paths)\n",
    "\n",
    "    return np.array([\n",
    "        [ morse_order(all_paths, sigma, tau) for tau in domain_simplices ] for sigma in codomain_simplices\n",
    "    ])\n",
    "\n",
    "def morse_chain_complex(Σ: PartialMatching) -> ChainComplex:\n",
    "    n = max(map(dim, Σ.critical())) + 1\n",
    "\n",
    "    return ChainComplex(\n",
    "        degrees=[ sum([ dim(s) == i for s in Σ.critical() ]) for i in range(n) ],\n",
    "        boundary_maps= [ _morse_boundary_map(Σ, i) for i in range(n) ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9344d5b",
   "metadata": {},
   "source": [
    "### 1.3.2 Example: Morse and Simplicial Chain Complexes for the $k$-Sphere\n",
    "\n",
    "To demonstrate the tremendous reduction in the size of the chain complexes afforded by discrete Morse theoretic techniques, we compute the homology of the $k$-sphere for $k = 4$ (though feel free to download the notebook play around with the value of $k$ in the following cell!) and observe the dimensions of the vector spaces in each chain complex and how large the matrices between them ordinarily are. The Morse complex, meanwhile, is *much* smaller.\n",
    "\n",
    "Still, as we mentioned earlier, the computation of all the $\\Sigma$-paths slows down as $k$ grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb8e2ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinary chain complex corresponding to the 4-sphere:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to \\mathbb R^{6} \\xrightarrow{\\left[\\begin{matrix}1 & 1 & 0 & 0 & 0 & 0\\\\-1 & 0 & 1 & 0 & 0 & 0\\\\0 & -1 & -1 & 0 & 0 & 0\\\\1 & 0 & 0 & 1 & 0 & 0\\\\0 & 1 & 0 & -1 & 0 & 0\\\\0 & 0 & 1 & 1 & 0 & 0\\\\-1 & 0 & 0 & 0 & 1 & 0\\\\0 & -1 & 0 & 0 & -1 & 0\\\\0 & 0 & -1 & 0 & 1 & 0\\\\0 & 0 & 0 & -1 & -1 & 0\\\\1 & 0 & 0 & 0 & 0 & 1\\\\0 & 1 & 0 & 0 & 0 & -1\\\\0 & 0 & 1 & 0 & 0 & 1\\\\0 & 0 & 0 & 1 & 0 & -1\\\\0 & 0 & 0 & 0 & 1 & 1\\end{matrix}\\right]}\\mathbb R^{15} \\xrightarrow{\\left[\\begin{array}{ccccccccccccccc}-1 & -1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & -1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 1 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 1 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\-1 & 0 & 0 & 0 & 0 & 0 & -1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & -1 & 0 & 0 & 0 & 0 & 1 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & -1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & -1 & 0 & 0 & -1 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & -1 & 0 & 0 & -1 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & -1 & 0 & 0 & -1 & -1 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & -1 & -1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & -1 & 0 & 0\\\\0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0\\\\0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & -1 & 0 & 0 & -1 & 0\\\\0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & -1 & 0 & 1 & 0\\\\0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & -1 & -1 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & -1\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & -1\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 1\\end{array}\\right]}\\mathbb R^{20} \\xrightarrow{\\left[\\begin{array}{cccccccccccccccccccc}1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\-1 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & -1 & 0 & 0 & -1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & -1 & 0 & 0 & -1 & 0 & -1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & -1 & 0 & 0 & -1 & 0 & -1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & -1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0\\\\0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & -1 & 0 & -1 & 0 & 1 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & -1 & 0 & -1 & -1 & 0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0\\\\0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & -1 & 0 & 1 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & -1 & -1 & 0\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & -1\\\\0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 1\\end{array}\\right]}\\mathbb R^{15} \\xrightarrow{\\left[\\begin{array}{ccccccccccccccc}-1 & -1 & -1 & -1 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\1 & 0 & 0 & 0 & 0 & -1 & -1 & -1 & -1 & 0 & 0 & 0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & -1 & -1 & -1 & 0 & 0 & 0\\\\0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & -1 & -1 & 0\\\\0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & -1\\\\0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 1\\end{array}\\right]}\\mathbb R^{6} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "6 --> 15 --> 20 --> 15 --> 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morse chain complex corresponding to the 4-sphere:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to \\mathbb R^{1} \\xrightarrow{}{0} \\xrightarrow{}{0} \\xrightarrow{}{0} \\xrightarrow{}\\mathbb R^{1} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "1 --> 0 --> 0 --> 0 --> 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 4\n",
    "K = SC.sphere(k)\n",
    "\n",
    "Σ = acyclic_partial_matching(K)\n",
    "\n",
    "C = chain_complex(K)\n",
    "M = morse_chain_complex(Σ)\n",
    "\n",
    "print(f\"Ordinary chain complex corresponding to the {k}-sphere:\")\n",
    "display(C.display_with_matrices(True))\n",
    "print(f\"Morse chain complex corresponding to the {k}-sphere:\")\n",
    "display(M.display_with_matrices(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406d669",
   "metadata": {},
   "source": [
    "Quite a bit smaller!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406184a",
   "metadata": {},
   "source": [
    "## 2 Cosheaves and Cosheaf Homology\n",
    "\n",
    "Having seen how simplicial homology may be computed, we turn our attention to homology with coefficients in a cosheaf. We begin by defining a cosheaf sitting over a simplicial complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702dc26",
   "metadata": {},
   "source": [
    "### 2.1 Cosheaves\n",
    "\n",
    "While a cosheaf is defined as a contravariant functor from a simplicial complex to the category of vector spaces (over a base field), we are not really able to capture much of this structure elegantly in Python. Instead we simply require a mapping from a pair of simplices to a matrix. We do provide a few simple examples of cosheaves, though, and a way to construct more complicated ones via sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddbd9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cosheaf:\n",
    "    def __init__(self, complex: SimplicialComplex, corestriction) -> None:\n",
    "        \"\"\"\n",
    "        `corestriction` should be a function taking a pair of simplices (`sigma`, `tau`) with `tau` a subset of `sigma` and returning a matrix.\n",
    "        \"\"\"\n",
    "        self.complex = complex\n",
    "        self.corestriction = corestriction                \n",
    "\n",
    "    @staticmethod\n",
    "    def skyscraper(complex: SimplicialComplex, simplex: Simplex):\n",
    "        return Cosheaf(\n",
    "            complex,\n",
    "            lambda s, t : np.eye(int(t == simplex), int(s == simplex))\n",
    "        )\n",
    "    \n",
    "    def sum(self, other):\n",
    "        \"\"\"\n",
    "        Assumes `self` and `other` are cosheaves over a common `SimplicialComplex`.\n",
    "        \"\"\"\n",
    "        def sum_corestriction(s, t):\n",
    "            A = self.corestriction(s, t)\n",
    "            B = other.corestriction(s, t)\n",
    "\n",
    "            return np.block([\n",
    "                [A, np.zeros((A.shape[0], B.shape[1]))],\n",
    "                [np.zeros((B.shape[0], A.shape[1])), B]\n",
    "            ])\n",
    "\n",
    "        return Cosheaf(self.complex, corestriction=sum_corestriction)\n",
    "    \n",
    "    @staticmethod\n",
    "    def constant(complex: SimplicialComplex, n: int):\n",
    "        return Cosheaf(\n",
    "            complex=complex, corestriction=lambda x, y : np.identity(n)\n",
    "        )\n",
    "    \n",
    "    def stalk_dimension(self, simplex):\n",
    "        return rank(self(simplex, simplex))\n",
    "\n",
    "    def __call__(self, bigger: Simplex, smaller: Simplex) -> np.array:\n",
    "        if not smaller.issubset(bigger):\n",
    "            return None\n",
    "        return self.corestriction(bigger, smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7dfa4",
   "metadata": {},
   "source": [
    "### 2.2 Cosheaf Homology\n",
    "\n",
    "Once we have a cosheaf defined, we may define the complex of chains with coefficients in the cosheaf, as we did in the body of the report. \n",
    "The homology of the resulting complex is what interests us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c34d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cosheaf_boundary_map(cosheaf: Cosheaf, n: int) -> np.array:\n",
    "    complex = cosheaf.complex\n",
    "\n",
    "    domain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, complex.simplices), key=simp_str)\n",
    "    codomain_simplices = sorted(filter(lambda simplex : dim(simplex) == n - 1, complex.simplices), key=simp_str)\n",
    "\n",
    "    rows = sum([ cosheaf.stalk_dimension(simplex) for simplex in codomain_simplices ])\n",
    "    cols = sum([ cosheaf.stalk_dimension(simplex) for simplex in domain_simplices ])\n",
    "\n",
    "    if rows == 0 and cols == 0:\n",
    "        return np.zeros((0, 0))\n",
    "    if rows == 0:\n",
    "        return np.zeros((0, cols))\n",
    "    if cols == 0:\n",
    "        return np.zeros((rows, 0))\n",
    "\n",
    "    return np.block([\n",
    "        [ order(tau, sigma) * cosheaf.corestriction(sigma, tau) for sigma in domain_simplices] for tau in codomain_simplices\n",
    "    ])\n",
    "\n",
    "def cosheaf_chain_complex(cosheaf: Cosheaf) -> ChainComplex:\n",
    "    n = max(map(dim, cosheaf.complex)) + 1\n",
    "\n",
    "    return ChainComplex(\n",
    "        degrees= [ sum([ cosheaf.stalk_dimension(simplex) for simplex in cosheaf.complex if dim(simplex) == i ]) for i in range(n) ],\n",
    "        boundary_maps = [ _cosheaf_boundary_map(cosheaf, i) for i in range(n) ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23161d0e",
   "metadata": {},
   "source": [
    "### 2.2.1 Example: Cosheaves and their Homologies\n",
    "\n",
    "We compute the homology of $S^{k_1} \\vee S^{k_2}$ with coefficients over the constant $\\mathbb R^2$ cosheaf $\\mathcal C_{\\mathbb R^2}$, the skyscraper ${\\rm sk}^\\tau$ (where $\\tau$ is an $m$-simplex), and over the cosheaf $\\mathcal C_{\\mathbb R^2} \\oplus {\\rm sk}^\\tau$.\n",
    "We recall that we expect\n",
    "$$ H_n(S^{k_1} \\vee S^{k_2}; \\mathcal C_{\\mathbb R^2}) =  H_n(S^{k_1} \\vee S^{k_2})^2,$$\n",
    "where the latter is $\\mathbb R$ in degrees $k_1$, $k_2$, and $0$, and otherwise vanishes. The skyscraper we expect to be $\\mathbb R$ at $n = \\dim \\tau$, and $0$ elsewhere.\n",
    "The homologies with coefficients in the sum cosheaf should be the sum of the homologies in the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7407848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain complexes:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to \\mathbb R^{14} \\xrightarrow{\\partial_5}\\mathbb R^{42} \\xrightarrow{\\partial_4}\\mathbb R^{80} \\xrightarrow{\\partial_3}\\mathbb R^{90} \\xrightarrow{\\partial_2}\\mathbb R^{62} \\xrightarrow{\\partial_1}\\mathbb R^{22} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "14 --> 42 --> 80 --> 90 --> 62 --> 22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to {0} \\xrightarrow{\\partial_5}\\mathbb R^{1} \\xrightarrow{\\partial_4}{0} \\xrightarrow{\\partial_3}{0} \\xrightarrow{\\partial_2}{0} \\xrightarrow{\\partial_1}{0} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "0 --> 1 --> 0 --> 0 --> 0 --> 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to \\mathbb R^{14} \\xrightarrow{\\partial_5}\\mathbb R^{43} \\xrightarrow{\\partial_4}\\mathbb R^{80} \\xrightarrow{\\partial_3}\\mathbb R^{90} \\xrightarrow{\\partial_2}\\mathbb R^{62} \\xrightarrow{\\partial_1}\\mathbb R^{22} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "14 --> 43 --> 80 --> 90 --> 62 --> 22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Betti Numbers for 5-sphere wedged 3-sphere via the constant ℝ^2 complex: [2, 0, 0, 2, 0]\n",
      "Betti Numbers for skyscraper over 4 dimensional simplex: [0, 0, 0, 0, 1]\n",
      "Betti Numbers for the sum of those two: [2, 0, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "k1 = 5\n",
    "k2 = 3\n",
    "m = 4\n",
    "\n",
    "K = SC.sphere(k1).wedge(SC.sphere(k2))\n",
    "\n",
    "constant_cosheaf = Cosheaf.constant(\n",
    "    K, n = 2\n",
    ")\n",
    "\n",
    "skyscraper_cosheaf = Cosheaf.skyscraper(\n",
    "    K, simplex=set(range(m + 1))\n",
    ")\n",
    "\n",
    "C1 = cosheaf_chain_complex(constant_cosheaf)\n",
    "C2 = cosheaf_chain_complex(skyscraper_cosheaf)\n",
    "C3 = cosheaf_chain_complex(constant_cosheaf.sum(skyscraper_cosheaf))\n",
    "\n",
    "print(\"Chain complexes:\\n\")\n",
    "\n",
    "display(C1)\n",
    "display(C2)\n",
    "display(C3)\n",
    "\n",
    "print(f\"\\nBetti Numbers for {k1}-sphere wedged {k2}-sphere via the constant ℝ^2 complex:\", [ C1.betti_number(n) for n in range(k + 1) ])\n",
    "print(f\"Betti Numbers for skyscraper over {m} dimensional simplex:\", [ C2.betti_number(n) for n in range(k + 1) ])\n",
    "print(f\"Betti Numbers for the sum of those two:\", [ C3.betti_number(n) for n in range(k + 1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1257d67",
   "metadata": {},
   "source": [
    "This is what we expect. As a hint for what's to come, note the degrees of the spaces in the chain complexes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365e563",
   "metadata": {},
   "source": [
    "### 2.3 Discrete Morse Theory\n",
    "\n",
    "As we did before in Section 1.3, a large reduction in space is afforded by translating everything over to a Morse complex. We have a bit more work to do to define the Morse chain complex with coefficients in a cosheaf, which we do as outlined in the report. Passing extra conditions into the `acyclic_partial_matching` function does not break the guarantee that the returned partial matching will be acyclic, since this is enforced by the condition that a pair is only added at some iteration when it is of the form $\\alpha < \\beta$ with $\\alpha$ being the only unpaired face of $\\beta$ at that iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08873b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosheaf_coherent_acyclic_partial_matching(cosheaf: Cosheaf, extra_conditions=lambda _ : True) -> PartialMatching: # What a mouthful!\n",
    "    is_invertible = lambda m : m.shape[0] == m.shape[1] and np.linalg.det(m) != 0\n",
    "    pair_is_coherent = lambda pair : is_invertible(cosheaf(bigger=pair.target, smaller=pair.source))\n",
    "\n",
    "    return acyclic_partial_matching(cosheaf.complex, extra_conditions=lambda pair : (pair_is_coherent(pair) and extra_conditions(pair)))\n",
    "\n",
    "def cosheaf_weight(cosheaf: Cosheaf, path: list[Simplex]) -> np.array:\n",
    "    terms = [\n",
    "        -np.linalg.inv(cosheaf_order(cosheaf, t=path[i + 1], s=path[i])) if i % 2 == 0\n",
    "        else cosheaf_order(cosheaf, t=path[i], s=path[i + 1])\n",
    "        for i in range(len(path) - 1)\n",
    "    ]\n",
    "\n",
    "    start = np.identity(terms[-1].shape[0] if terms else 1)\n",
    "    return reduce(np.matmul, reversed(terms), start)\n",
    "\n",
    "def cosheaf_order(cosheaf: Cosheaf, s: Simplex, t: Simplex) -> np.array:\n",
    "    return np.zeros((cosheaf.stalk_dimension(s), cosheaf.stalk_dimension(t))) if order(s, t) == 0 else order(s, t) * cosheaf(t, s)\n",
    "\n",
    "def cosheaf_morse_order(cosheaf: Cosheaf, matching: PartialMatching, s: Simplex, t: Simplex) -> np.array:    \n",
    "    return cosheaf_order(cosheaf, s, t) + sum([ \n",
    "        cosheaf_order(cosheaf, s, p[-1]) @ cosheaf_weight(cosheaf, p) @ cosheaf_order(cosheaf, p[0], t) for p in matching.critical_paths() if p\n",
    "    ])\n",
    "\n",
    "def _cosheaf_morse_boundary_map(cosheaf: Cosheaf, matching: PartialMatching, n: int):\n",
    "    critical_simplices = matching.critical()\n",
    "\n",
    "    # bucket simplices by dimension and sort them in a semi-reasonable way for prettiness\n",
    "    domain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, critical_simplices), key=simp_str)\n",
    "    codomain_simplices = sorted(filter(lambda simplex : dim(simplex) == n - 1, critical_simplices), key=simp_str)\n",
    "\n",
    "    rows = sum([ cosheaf.stalk_dimension(simplex) for simplex in codomain_simplices ])\n",
    "    cols = sum([ cosheaf.stalk_dimension(simplex) for simplex in domain_simplices ])\n",
    "\n",
    "    if rows == 0 and cols == 0:\n",
    "        return np.zeros((0, 0))\n",
    "    if rows == 0:\n",
    "        return np.zeros((0, cols))\n",
    "    if cols == 0:\n",
    "        return np.zeros((rows, 0))\n",
    "\n",
    "    return np.block([\n",
    "        [ cosheaf_morse_order(cosheaf, matching, tau, sigma) for sigma in domain_simplices ] for tau in codomain_simplices\n",
    "    ])\n",
    "\n",
    "\n",
    "def cosheaf_morse_chain_complex(cosheaf: Cosheaf, Σ: PartialMatching) -> ChainComplex:\n",
    "    n = max(map(dim, Σ.critical())) + 1\n",
    "\n",
    "    return ChainComplex(\n",
    "        degrees= [ sum([ cosheaf.stalk_dimension(simplex) for simplex in Σ.critical() if dim(simplex) == i ]) for i in range(n) ],\n",
    "        boundary_maps = [ _cosheaf_morse_boundary_map(cosheaf, Σ, i) for i in range(n) ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2442e7",
   "metadata": {},
   "source": [
    "### Example 2.3.1\n",
    "\n",
    "We repeat the computations from Example 2.2.1, only this time applying the code we've written to use discrete Morse theory to find smaller chain complexes whose homologies agree with the ones we calculated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa7697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain complexes:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to \\mathbb R^{2} \\xrightarrow{\\partial_5}{0} \\xrightarrow{\\partial_4}\\mathbb R^{2} \\xrightarrow{\\partial_3}{0} \\xrightarrow{\\partial_2}{0} \\xrightarrow{\\partial_1}\\mathbb R^{2} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "2 --> 0 --> 2 --> 0 --> 0 --> 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to {0} \\xrightarrow{\\partial_5}\\mathbb R^{1} \\xrightarrow{\\partial_4}{0} \\xrightarrow{\\partial_3}{0} \\xrightarrow{\\partial_2}{0} \\xrightarrow{\\partial_1}{0} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "0 --> 1 --> 0 --> 0 --> 0 --> 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\cdots \\to 0 \\to \\mathbb R^{4} \\xrightarrow{\\partial_5}\\mathbb R^{3} \\xrightarrow{\\partial_4}\\mathbb R^{2} \\xrightarrow{\\partial_3}{0} \\xrightarrow{\\partial_2}{0} \\xrightarrow{\\partial_1}\\mathbb R^{2} \\to 0 \\to \\cdots$$"
      ],
      "text/plain": [
       "4 --> 3 --> 2 --> 0 --> 0 --> 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Betti Numbers for 5-sphere wedged 3-sphere via the constant ℝ^2 complex: [2, 0, 0, 2, 0]\n",
      "Betti Numbers for skyscraper over 4 dimensional simplex: [0, 0, 0, 0, 1]\n",
      "Betti Numbers for the sum of those two: [2, 0, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "k1 = 5\n",
    "k2 = 3\n",
    "m = 4\n",
    "\n",
    "K = SC.sphere(k1).wedge(SC.sphere(k2))\n",
    "\n",
    "constant_cosheaf = Cosheaf.constant(\n",
    "    K, n = 2\n",
    ")\n",
    "\n",
    "skyscraper_cosheaf = Cosheaf.skyscraper(\n",
    "    K, simplex=set(range(m + 1))\n",
    ")\n",
    "\n",
    "Σ1 = cosheaf_coherent_acyclic_partial_matching(constant_cosheaf)\n",
    "Σ2 = cosheaf_coherent_acyclic_partial_matching(skyscraper_cosheaf)\n",
    "Σ3 = cosheaf_coherent_acyclic_partial_matching(constant_cosheaf.sum(skyscraper_cosheaf))\n",
    "\n",
    "C1 = cosheaf_morse_chain_complex(constant_cosheaf, Σ1)\n",
    "C2 = cosheaf_morse_chain_complex(skyscraper_cosheaf, Σ2)\n",
    "C3 = cosheaf_morse_chain_complex(constant_cosheaf.sum(skyscraper_cosheaf), Σ3)\n",
    "\n",
    "print(\"Chain complexes:\\n\")\n",
    "\n",
    "display(C1)\n",
    "display(C2)\n",
    "display(C3)\n",
    "\n",
    "print(f\"\\nBetti Numbers for {k1}-sphere wedged {k2}-sphere via the constant ℝ^2 complex:\", [ C1.betti_number(n) for n in range(k + 1) ])\n",
    "print(f\"Betti Numbers for skyscraper over {m} dimensional simplex:\", [ C2.betti_number(n) for n in range(k + 1) ])\n",
    "print(f\"Betti Numbers for the sum of those two:\", [ C3.betti_number(n) for n in range(k + 1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aec40f",
   "metadata": {},
   "source": [
    "Notice that the Morse chain complexes are much smaller than the ones we originally computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973813d9",
   "metadata": {},
   "source": [
    "## 3 Mayer-Vietoris\n",
    "\n",
    "In this section, we will apply the previous techinques to the case of Mayer-Veitoris sequences, in which we may decompose a simplicial complex $K$ as a union of two subcomplexes $L$ and $M$.\n",
    "These decompositions induce a short exact sequence of chain complexes\n",
    "$$ 0 \\to C_\\bullet(L \\cap M) \\to C_\\bullet(L) \\oplus C_\\bullet(M) \\to C_\\bullet(K) $$\n",
    "where the chains take values in some field or cosheaf.\n",
    "This in turn, by the snake lemma, induces a long exact sequence of homology: this is the Mayer-Vietoris sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fda420",
   "metadata": {},
   "source": [
    "### 3.1 Chain Maps\n",
    "\n",
    "We first define a chain map as a collection of maps between $C_n$ and $D_n$ for two chain complexes $C_\\bullet$ and $D_\\bullet$ and check that the appropriate squares commute.\n",
    "We also define a way to handle the important class of chain maps between simplicial chain complexes $C_\\bullet(K) \\to C_\\bullet(L)$ that are induced by simplicial maps $K \\to L$.\n",
    "Homology is also functorial, so chain maps induce maps on homology, which we compute via the `on_homology` method.\n",
    "\n",
    "To better explain the thought process there, we recall that a map $f : C_\\bullet \\to D_\\bullet$ extends to a map on homology via $[x] \\mapsto [f_n(x)]$ in degree $n$.\n",
    "Recall that we have been viewing homology as the orthogonal complement $H_n(C) \\cong ({\\rm im} \\, \\partial_{n + 1})^\\bot$ where the ambient space is $\\ker \\partial_n$.\n",
    "Under this identification, $H_n(C)$ includes into $\\ker \\partial_n$ and therefore into $C_n$, and so we have the following diagram,  where $i_n^C$ is the inclusion $H_n(C) \\hookrightarrow C_n$.\n",
    "\n",
    "<!-- https://q.uiver.app/#q=WzAsNCxbMCwwLCJDX24iXSxbMSwwLCJEX24iXSxbMCwxLCJIX24oQykiXSxbMSwxLCJIX24oRCkiXSxbMiwwLCJpX25eQyJdLFswLDEsImZfbiJdLFszLDEsImlfbl5EIiwyXSxbMiwzLCJIX24oZikiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0= -->\n",
    "<iframe class=\"quiver-embed\" src=\"https://q.uiver.app/#q=WzAsNCxbMCwwLCJDX24iXSxbMSwwLCJEX24iXSxbMCwxLCJIX24oQykiXSxbMSwxLCJIX24oRCkiXSxbMiwwLCJpX25eQyJdLFswLDEsImZfbiJdLFszLDEsImlfbl5EIiwyXSxbMiwzLCJIX24oZikiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=&embed\" width=\"358\" height=\"304\" style=\"border-radius: 8px; border: none;\"></iframe>\n",
    "\n",
    "Now commutativity of this square means that $i_n^D \\circ H_n(f) = f_n \\circ i_n^C$, so we can obtain $H_n(f)$ by finding a left inverse $L$ to $i_n^D$; then $H_n(f) = L \\circ f_n \\circ i_n^C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf1eb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainMap:\n",
    "    def __init__(self, domain: ChainComplex, codomain: ChainComplex, maps: tuple[np.array]) -> None:\n",
    "        self.domain = domain\n",
    "        self.codomain = codomain\n",
    "        self.__maps = maps\n",
    "        self.test_dims()        \n",
    "        self.test_naturality()\n",
    "    \n",
    "    def test_dims(self):\n",
    "        assert all_satisfy(\n",
    "            lambda i : self.map(i).shape == (self.codomain.degree(i), self.domain.degree(i)),\n",
    "            range(self.max_dim() + 1)\n",
    "        ), f\"Maps have unexpected shapes {[ x.shape for x in self.__maps ]} for degrees {[ (self.domain.degree(i), self.codomain.degree(i)) for i in range(self.max_dim() + 1) ]}\"\n",
    "    \n",
    "    def test_naturality(self):\n",
    "        assert all_satisfy(\n",
    "            lambda i : np.array_equal(self.map(i - 1) @ self.domain.boundary_map(i), self.codomain.boundary_map(i) @ self.map(i)),\n",
    "            range(self.max_dim() + 1)\n",
    "        ), f\"Commuting square does not commute :(\"\n",
    "\n",
    "        \n",
    "    def max_dim(self):\n",
    "        return max(self.domain.max_dim(), self.codomain.max_dim())\n",
    "\n",
    "    def map(self, i: int) -> np.array:\n",
    "        if 0 <= i and i < len(self.__maps):\n",
    "            return self.__maps[i]\n",
    "        return np.zeros((0, 0))\n",
    "    \n",
    "    def __call__(self, i: int) -> np.array:\n",
    "        return self.map(i)\n",
    "    \n",
    "    @staticmethod\n",
    "    def builder(C: ChainComplex, D: ChainComplex, map_builder):\n",
    "        return ChainMap(\n",
    "            domain=C,\n",
    "            codomain=D,\n",
    "            maps=list(map(map_builder, range(max(C.max_dim(), D.max_dim()) + 1)))\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def from_simplicial_map(f, K: SimplicialComplex, L: SimplicialComplex):\n",
    "        domain = chain_complex(K)\n",
    "        codomain = chain_complex(L)\n",
    "\n",
    "        def define_map(n):\n",
    "            domain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, K), key=simp_str)\n",
    "            codomain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, L), key=simp_str)\n",
    "\n",
    "            M = np.zeros((len(codomain_simplices), len(domain_simplices)))\n",
    "\n",
    "            for i in range(len(domain_simplices)):\n",
    "                s = domain_simplices[i]\n",
    "                \n",
    "                if dim(f(s)) == n:\n",
    "                    M[codomain_simplices.index(f(s))][i] = 1\n",
    "            \n",
    "            return M\n",
    "        \n",
    "        return ChainMap.builder(domain, codomain, map_builder=define_map)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_inclusion(C: ChainComplex, D: ChainComplex, domain_simplices: set[Simplex], codomain_simplices: set[Simplex], cosheaf: Cosheaf=None):\n",
    "        sd = lambda simplex : cosheaf.stalk_dimension(simplex) if cosheaf else 1\n",
    "\n",
    "        def define_map(n):\n",
    "            ds = sorted([s for s in domain_simplices if dim(s) == n], key=simp_str)\n",
    "            cs = sorted([t for t in codomain_simplices if dim(t) == n], key=simp_str)\n",
    "\n",
    "            M = [\n",
    "                [ np.identity(sd(sigma)) if sigma == tau else np.zeros((sd(tau), sd(sigma))) for sigma in ds ] for tau in cs\n",
    "            ]\n",
    "\n",
    "            if not M or not M[0]:\n",
    "                return np.zeros(\n",
    "                    (sum([ sd(t) for t in cs]), sum([sd(s) for s in ds]))\n",
    "                )\n",
    "            \n",
    "            return np.block(M)\n",
    "        \n",
    "        return ChainMap.builder(C, D, define_map)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_partial_matching_restriction(Σ: PartialMatching, L: SimplicialComplex, cosheaf: Cosheaf=None):\n",
    "        \"\"\"\n",
    "        Needs Σ to be an L-compatible and a cosheaf-compatible partial matching.\n",
    "        \"\"\"\n",
    "        domain_simplices = set(L.simplices).intersection(Σ.critical())\n",
    "        codomain_simplices = Σ.critical()\n",
    "\n",
    "        C = cosheaf_morse_chain_complex(cosheaf=cosheaf, Σ=Σ.restrict(L))\n",
    "        D = cosheaf_morse_chain_complex(cosheaf=cosheaf, Σ=Σ)\n",
    "\n",
    "        return ChainMap.from_inclusion(C, D, domain_simplices, codomain_simplices, cosheaf)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_critical_map(f, M1: PartialMatching, M2: PartialMatching):\n",
    "        domain = morse_chain_complex(M1)\n",
    "        codomain = morse_chain_complex(M2)\n",
    "\n",
    "        def define_map(n):\n",
    "            domain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, M1.critical()), key=simp_str)\n",
    "            codomain_simplices = sorted(filter(lambda simplex : dim(simplex) == n, M2.critical()), key=simp_str)\n",
    "\n",
    "            A = np.zeros((len(codomain_simplices), len(domain_simplices)))\n",
    "\n",
    "            for i in range(len(domain_simplices)):\n",
    "                s = domain_simplices[i]\n",
    "                \n",
    "                if dim(f(s)) == n:\n",
    "                    A[codomain_simplices.index(f(s))][i] = 1\n",
    "            \n",
    "            return A\n",
    "        \n",
    "        return ChainMap.builder(domain, codomain, map_builder=define_map)\n",
    "\n",
    "    def on_homology(self, n: int) -> np.array:\n",
    "        H1 = self.domain.homology_basis(n)\n",
    "        H2 = self.codomain.homology_basis(n)\n",
    "        \n",
    "        A = self.map(n)\n",
    "\n",
    "        return left_inverse(H2) @ A @ H1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c055d",
   "metadata": {},
   "source": [
    "### 3.2 Snake Lemma\n",
    "\n",
    "A short exact sequence of chain complexes\n",
    "$$ 0 \\to A \\xrightarrow{f_\\bullet} B \\xrightarrow{g_\\bullet} C \\to 0 $$\n",
    "gives rise to the following long exact sequence of vector spaces\n",
    "$$ \\cdots \\to H_n(A) \\xrightarrow{H_n(f)} H_n(B) \\xrightarrow{H_n(g)} H_n(C) \\xrightarrow{\\delta_n} H_{n - 1}(A) \\xrightarrow{H_{n - 1}(f)} H_{n - 1}(B) \\to \\cdots, $$\n",
    "where $H_n(f)$ and $H_n(g)$ are as we already described, and $\\delta_n$ arises from the snake lemma. More specifically, $\\delta [c] =: [a]$ is defined by\n",
    "$f_{n - 1}(a) = \\partial^B_n(b)$, where $g(b) = c$.\n",
    "\n",
    "The fact that this all works is covered in the course, but we must implement it explicitly here. So we find a left inverse $L_n$ to $f_n$ and a right inverse $R_n$ to $g_n$.\n",
    "These exist because exactness guarantees that $f_n$ is injective and $g_n$ is surjective.\n",
    "We then note that defining $a = (L_n \\circ \\partial^B_n \\circ R_n)(c)$ and $b = R_n(c)$ for $c \\in C_n$, we obtain\n",
    "$f(a) = \\partial^B_n(b)$ and $g(b) = c$, as we had desired.\n",
    "\n",
    "Now we have a diagram as below: finding a left inverse to $i_{n - 1}^A$ allows us to solve for $\\delta_n$.\n",
    "<!-- https://q.uiver.app/#q=WzAsNCxbMCwxLCJIX3tuIC0gMX0oQSkiXSxbMCwwLCJBX3tuIC0gMX0iXSxbMiwwLCJDX3tufSJdLFsyLDEsIkhfbihDKSJdLFsyLDEsIkxfbiBcXGNpcmMgXFxwYXJ0aWFsX25eQiBcXGNpcmMgUl9uIiwyXSxbMywyLCJpX25eQyIsMl0sWzAsMSwiaV97biAtIDF9XkEiXSxbMywwLCJcXGRlbHRhX24iLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0= -->\n",
    "<iframe class=\"quiver-embed\" src=\"https://q.uiver.app/#q=WzAsNCxbMCwxLCJIX3tuIC0gMX0oQSkiXSxbMCwwLCJBX3tuIC0gMX0iXSxbMiwwLCJDX3tufSJdLFsyLDEsIkhfbihDKSJdLFsyLDEsIkxfbiBcXGNpcmMgXFxwYXJ0aWFsX25eQiBcXGNpcmMgUl9uIiwyXSxbMywyLCJpX25eQyIsMl0sWzAsMSwiaV97biAtIDF9XkEiXSxbMywwLCJcXGRlbHRhX24iLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifX19XV0=&embed\" width=\"511\" height=\"304\" style=\"border-radius: 8px; border: none;\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b022b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connecting_homomorphism(f: ChainMap, g: ChainMap, n: int, verbose=False):\n",
    "    \"\"\"\n",
    "    Note we assume that 0 --> f.domain --> f.codomain == g.domain --> g.codomain --> 0 is a short exact sequence of chain complexes.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"f(n - 1)\")\n",
    "        print(f(n - 1))\n",
    "        print(\"\\n\")\n",
    "        print(g(n))\n",
    "\n",
    "    L = left_inverse(f(n - 1))\n",
    "    R = right_inverse(g(n))\n",
    "    \n",
    "    M = left_inverse(f.domain.homology_basis(n - 1))\n",
    "\n",
    "    return M @ L @ f.codomain.boundary_map(n) @ R @ g.codomain.homology_basis(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d823d",
   "metadata": {},
   "source": [
    "### 3.2.1 Why does the Morse Complex Help?\n",
    "\n",
    "In the code above, we find a `left_inverse` of the map $f$ and `right_inverse` of the map $g$, which are chain maps. If we were to use the chain complexes $(C_\\bullet(K; \\mathcal C), \\partial^{\\mathcal C}_\\bullet)$ as a source for this calculation, we would have to take inverses and multiply together matrices that are quite large when there are many simplices.\n",
    "Indeed, multiplication of a $k \\times m$ matrix by an $m \\times n$ matrix is $O(kmn)$, and the method we use for finding left and right inverses relies on factorizing into orthogonal and upper diagonal matrices, which is also a costly operation.\n",
    "More details on complexity of matrix operations may be found online <a href=\"https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra\">here</a> (also cited in the references of the report).\n",
    "\n",
    "In any case, there is a clear impetus to reduce the size of any chain complexes where possible, and since we are only interested in our complexes up to quasi-isomorphism, there is no salient information lost by passing down to the Morse complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14deef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_chain_maps(f: ChainMap, g: ChainMap, same_domain: bool=False, same_codomain: bool=False, mult: tuple[float, float]=(1., 1.)) -> ChainMap:\n",
    "    a, b = mult\n",
    "    \n",
    "    if same_domain and same_codomain:\n",
    "        return ChainMap.builder(\n",
    "            f.domain,\n",
    "            f.codomain,\n",
    "            lambda n : a * f(n) + b * g(n)\n",
    "        )\n",
    "    if same_domain:\n",
    "        map_builder_same_domain = lambda n : np.block([[a * f(n)], [b * g(n)]])\n",
    "        return ChainMap.builder(\n",
    "            f.domain,\n",
    "            f.codomain.sum(g.codomain),\n",
    "            map_builder_same_domain\n",
    "        )\n",
    "    if same_codomain:\n",
    "        map_builder_same_codomain = lambda n : np.block([[a * f(n), b * g(n)]])\n",
    "        return ChainMap.builder(\n",
    "            f.domain.sum(g.domain),\n",
    "            f.codomain,\n",
    "            map_builder_same_codomain\n",
    "        )\n",
    "    map_builder_different = lambda n : np.block([\n",
    "            [mult[0] * f(n), np.zeros((f(n).shape[0], g(n).shape[1]))],\n",
    "            [np.zeros((g(n).shape[0], f(n).shape[1])), mult[1] * g(n)]\n",
    "        ])\n",
    "\n",
    "    return ChainMap.builder(\n",
    "        f.domain.sum(g.domain),\n",
    "        f.codomain.sum(g.codomain),\n",
    "        map_builder_different\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf6184",
   "metadata": {},
   "source": [
    "We'll introduce a class here that encapsulates what it means to be a Mayer-Vietoris sequence: to be a long exact sequence arising from a chain complex that arises from inclusions of $L \\cap M$ into $L$ and $M$ and then into $L \\cup M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05430bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvsi(n, i):\n",
    "    return 3 * n + (2 - i)\n",
    "\n",
    "def isvm(n):\n",
    "    return (n // 3, 2 - (n % 3))\n",
    "\n",
    "class MayerVietoris:\n",
    "    def __init__(self, part1, part2, intersection, union, chain_complex: ChainComplex) -> None:\n",
    "        self.part1 = part1\n",
    "        self.part2 = part2\n",
    "        self.intersection = intersection\n",
    "        self.union = union\n",
    "        self._chain_complex = chain_complex\n",
    "        self.show_matrices = False\n",
    "        self.should_display_with_matrices = False\n",
    "\n",
    "    def max_dim(self):\n",
    "        n, _ = isvm(self._chain_complex.max_dim())\n",
    "        return n\n",
    "\n",
    "    def degree(self, n: int, i):\n",
    "        return self._chain_complex.degree(mvsi(n, i))\n",
    "    \n",
    "    def map(self, n: int, i):\n",
    "        return self._chain_complex.boundary_map(mvsi(n, i))\n",
    "    \n",
    "    def display_with_matrices(self):\n",
    "        self.should_display_with_matrices = True\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_inclusions(alpha, beta, i, j, L: SimplicialComplex, M: SimplicialComplex):\n",
    "        L_cap_M = SimplicialComplex(set(L.simplices).intersection(M.simplices), no_assert=True)\n",
    "        L_cup_M = SimplicialComplex(set(L.simplices).union(M.simplices), no_assert=True)\n",
    "\n",
    "        f = sum_chain_maps(alpha, beta, same_domain=True)\n",
    "        g = sum_chain_maps(i, j, same_codomain=True, mult=(1, -1))\n",
    "        \n",
    "        max_dim = max(map(dim, L_cup_M.simplices))\n",
    "        max_degree = 3 * max_dim + 2\n",
    "\n",
    "        def degree(n, i):\n",
    "            if i == 2:\n",
    "                return g.codomain.betti_number(n)\n",
    "            if i == 1:\n",
    "                return g.domain.betti_number(n)\n",
    "            if i == 0:\n",
    "                return f.domain.betti_number(n)\n",
    "            return None\n",
    "\n",
    "        def get_map(n, i):\n",
    "            if i == 2:\n",
    "                return connecting_homomorphism(f, g, n)\n",
    "            if i == 1:\n",
    "                return g.on_homology(n)\n",
    "            if i == 0:\n",
    "                return f.on_homology(n)\n",
    "            \n",
    "        cc = ChainComplex(\n",
    "            degrees=[ degree(*isvm(n)) for n in range(max_degree) ],\n",
    "            boundary_maps=[ get_map(*isvm(n)) for n in range(max_degree) ]\n",
    "        )\n",
    "\n",
    "        return MayerVietoris(L, M, L_cap_M, L_cup_M, cc)\n",
    "\n",
    "    @staticmethod\n",
    "    def morse_cosheaf(L: SimplicialComplex, M: SimplicialComplex, cosheaf: Cosheaf) -> None:\n",
    "        \"\"\"\n",
    "        Must be that L U M = cosheaf.complex.\n",
    "        \"\"\"\n",
    "        L_cap_M = SimplicialComplex(simplices=L.simplices.intersection(M.simplices))\n",
    "\n",
    "        L_compatible = lambda pair : ((pair.source in L) == (pair.target in L))\n",
    "        M_compatible = lambda pair : ((pair.source in M) == (pair.target in M))\n",
    "        Σ = cosheaf_coherent_acyclic_partial_matching(cosheaf, extra_conditions=lambda pair : L_compatible(pair) and M_compatible(pair))\n",
    "\n",
    "        alpha = ChainMap.from_partial_matching_restriction(Σ.restrict(L), L_cap_M, cosheaf)\n",
    "        beta = ChainMap.from_partial_matching_restriction(Σ.restrict(M), L_cap_M, cosheaf)\n",
    "        i = ChainMap.from_partial_matching_restriction(Σ, L, cosheaf)\n",
    "        j = ChainMap.from_partial_matching_restriction(Σ, M, cosheaf)\n",
    "\n",
    "        return MayerVietoris.from_inclusions(alpha, beta, i, j, L, M)\n",
    "\n",
    "    @staticmethod\n",
    "    def simplicial(L: SimplicialComplex, M: SimplicialComplex) -> None:\n",
    "        L_cap_M = SimplicialComplex(set(L.simplices).intersection(M.simplices), no_assert=True)\n",
    "        L_cup_M = SimplicialComplex(set(L.simplices).union(M.simplices), no_assert=True)\n",
    "\n",
    "        id = lambda x : x\n",
    "\n",
    "        alpha = ChainMap.from_simplicial_map(id, L_cap_M, L)\n",
    "        beta = ChainMap.from_simplicial_map(id, L_cap_M, M)\n",
    "        i = ChainMap.from_simplicial_map(id, L, L_cup_M)\n",
    "        j = ChainMap.from_simplicial_map(id, M, L_cup_M)\n",
    "\n",
    "        return MayerVietoris.from_inclusions(alpha, beta, i, j, L, M) # (L, M, L_cap_M, L_cup_M, cc)\n",
    "    \n",
    "\n",
    "    def _repr_latex_(self) -> str:\n",
    "        arrow_no_matrices = lambda n, i : f\"H_{n}(f)\" if i == 0 else \"H_{n}(g)\" if i == 1 else f\"\\\\delta_{n}\"\n",
    "        arrow = lambda n, i : (latex(Matrix(self.map(n, i))) if all(self.map(n, i).shape) else '') if self.should_display_with_matrices else arrow_no_matrices(n, i)\n",
    "        space = lambda n, i : \"\\\\mathbb R^{\" + str(self.degree(n, i)) if self.degree(n, i) else \"{0\"\n",
    "\n",
    "        return \"\\\\begin{align*}\" + \"\\\\\\\\ \\\\to\".join([\n",
    "            \"\".join([ \"&\" + (i * \"&\") + space(n, i) + \"}\\\\xrightarrow{\" + arrow(n, i) + \"}\" for i in range(3) ]) for n in range(self.max_dim(), -1, -1)\n",
    "        ]) + \"\\\\end{align*}\"\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        rows = [ \" --> \".join([ str(self.degree(n, i)) for i in range(3) ]) for n in range(self.max_dim(), -1, -1) ]\n",
    "        return \" -->\\n\".join(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5dd5c",
   "metadata": {},
   "source": [
    "### 3.2.2 Example\n",
    "\n",
    "We decompose $K = \\partial \\Delta(3)$ as the union of $L$ and $M$ where $L = \\Delta(2)$ and $M = \\Lambda^3_3$, i.e everything but the face opposite $3$ of $\\partial \\Delta(3)$.\n",
    "$L$ and $M$ intersect in $\\partial \\Delta(2)$.\n",
    "\n",
    "We put a peculiar cosheaf over this simplicial complex for the purposes of a demonstration, written as the sum of a few skyscrapers and a constant cosheaf.\n",
    "We then find the Mayer-Vietoris sequence associated to this decomposition, where we leverage the power of discrete Morse theory to find a smaller chain complex than the one we'd typically define to simplify calculation.\n",
    "\n",
    "The code that does this lies is in the `MayerVietoris.morse_cosheaf` method, and finds an acyclic partial matching that is compatible with the cosheaf and both $L$ and $M$, in the sense we defined in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b55c7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{align*}&{0}\\xrightarrow{H_2(f)}&&{0}\\xrightarrow{H_{n}(g)}&&&\\mathbb R^{3}\\xrightarrow{\\delta_2}\\\\ \\to&\\mathbb R^{3}\\xrightarrow{H_1(f)}&&{0}\\xrightarrow{H_{n}(g)}&&&{0}\\xrightarrow{\\delta_1}\\\\ \\to&\\mathbb R^{6}\\xrightarrow{H_0(f)}&&\\mathbb R^{12}\\xrightarrow{H_{n}(g)}&&&\\mathbb R^{6}\\xrightarrow{\\delta_0}\\end{align*}"
      ],
      "text/plain": [
       "0 --> 0 --> 3 -->\n",
       "3 --> 0 --> 0 -->\n",
       "6 --> 12 --> 6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = SC.sphere(2)\n",
    "\n",
    "L = SC.ball(2)\n",
    "M = SimplicialComplex.generated_by(\n",
    "    { f for f in faces(Simplex({0, 1, 2, 3})) if 3 in f }\n",
    ")\n",
    "\n",
    "cosheaf = reduce(lambda x, y : x.sum(y), [ Cosheaf.skyscraper(K, {v}) for v in [0, 1, 2] ], Cosheaf.constant(K, n = 0)).sum(Cosheaf.constant(K, 3)) # some wacky looking cosheaf!\n",
    "\n",
    "MayerVietoris.morse_cosheaf(L, M, cosheaf) # .display_with_matrices() this looks a bit wonky with the align environment..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb74d81",
   "metadata": {},
   "source": [
    "## 4. Possible Extensions\n",
    "\n",
    "Aside from the routine cleaning of hastily written code and rooting out of whatever bugs may linger unnoticed, there are a number of possible directions we might take to better this notebook. \n",
    "\n",
    "<ul>\n",
    "    <li> More diverse examples of cosheaves: This would have a primarily pedagogic benefit on the notebook. </li><br/>\n",
    "    <li> More detailed analysis of algorithms: The code written for this project was written with the intent of being functional but not for being optimal. For this reason, the algorithms that were implemented were not carefully considered for efficiency, and it would be interesting and worthwhile to spend some time deciding which aspects of the program can be made faster, and which are fundamentally slow. As an example, it seems unlikely that the implementation of the computation of the boundary operator for Morse complexes is at present optimal. Investigating whether that is the case would be a useful extension.  </li><br/>\n",
    "    <li> Applications to TDA: It would be an interesting extension of this project to research what cosheaves are frequently used in topological data analysis and to take an actual dataset, adapt the techinques here to be compatible with filtrations, and try to learn something meaningful about the dataset by computing its homology groups.\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
